# similarity_analyzer.py

import os
import json
import glob
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import google.generativeai as genai
from google.generativeai.types import GenerationConfig
from dotenv import load_dotenv

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° Gemini ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
genai.configure(api_key=os.getenv("GEMINI_API_KEY_3"))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìœ í‹¸: ìµœì‹  features_*.json ì°¾ê¸°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def find_latest_features_file():
    existing = glob.glob("features_*.json")
    if not existing:
        return None
    existing_nums = [
        int(f.split("_")[-1].split(".")[0])
        for f in existing
        if f.split("_")[-1].split(".")[0].isdigit()
    ]
    if not existing_nums:
        return None
    latest_index = max(existing_nums)
    return f"features_{latest_index}.json"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì…ë ¥ ë°ì´í„° ë¡œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_data():
    # 1) ê¸°íšì„œ ë¡œë“œ
    plan_file = find_latest_features_file()
    if not plan_file:
        print("âŒ ì²˜ë¦¬í•  ê¸°íšì„œ íŒŒì¼(features_*.json)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, None

    try:
        with open(plan_file, "r", encoding="utf-8") as f:
            plan_data = json.load(f).get("ì •ì œê¸°íšì„œ")
        plan_text = json.dumps(plan_data, ensure_ascii=False)
    except Exception as e:
        print(f"âŒ '{plan_file}' íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {e}")
        return None, None

    # 2) í›„ë³´ ë¦¬í¬ ë¡œë“œ
    try:
        with open("github_repositories.json", "r", encoding="utf-8") as f:
            repos_data = json.load(f)
    except FileNotFoundError:
        print("âŒ 'github_repositories.json' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € í›„ë³´ë¥¼ ìƒì„±í•˜ì„¸ìš”.")
        return None, None
    except Exception as e:
        print(f"âŒ 'github_repositories.json' íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {e}")
        return None, None

    return plan_text, repos_data

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê°œë³„ ë¦¬í¬ì§€í† ë¦¬ ì‹¬ì¸µ ë¶„ì„ (Gemini)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def analyze_similarity_with_gemini(plan_text, repo_readme, repo_name):
    print(f"    âœ¨ Gemini APIë¡œ '{repo_name}' ìƒì„¸ ë¶„ì„ ì¤‘...")
    prompt = f"""
ë‹¹ì‹ ì€ ì†Œí”„íŠ¸ì›¨ì–´ í”„ë¡œì íŠ¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ í”„ë¡œì íŠ¸ ê¸°íšì„œì™€ GitHub ë¦¬í¬ì§€í† ë¦¬ì˜ README ë‚´ìš©ì„ ë¹„êµí•˜ì—¬, ë‘ í”„ë¡œì íŠ¸ ê°„ì˜ í•µì‹¬ì ì¸ ìœ ì‚¬ì ê³¼ ì°¨ì´ì ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

---
### ğŸ“œ ì›ë³¸ í”„ë¡œì íŠ¸ ê¸°íšì„œ ìš”ì•½:
{plan_text[:1500]}
---
### ğŸ“„ GitHub ë¦¬í¬ì§€í† ë¦¬ README ìš”ì•½:
{repo_readme[:1500]}
---

### âœï¸ ë¶„ì„ ìš”ì²­:
1. **ìœ ì‚¬ì **: ë‘ í”„ë¡œì íŠ¸ê°€ ì–´ë–¤ ì ì—ì„œ ë¹„ìŠ·í•œ ëª©í‘œ, ê¸°ëŠ¥, ê¸°ìˆ  ìŠ¤íƒì„ ê°€ì§€ê³  ìˆëŠ”ì§€ 2~3ê°€ì§€ í•µì‹¬ í•­ëª©ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
2. **ì°¨ì´ì **: ë‘ í”„ë¡œì íŠ¸ì˜ ëª©ì , êµ¬í˜„ ë°©ì‹, ê¸°ëŠ¥ ë²”ìœ„ ë“±ì—ì„œ ë‚˜íƒ€ë‚˜ëŠ” ëª…í™•í•œ ì°¨ì´ì ì„ 2~3ê°€ì§€ í•µì‹¬ í•­ëª©ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.

### ğŸ“‹ ì¶œë ¥ í˜•ì‹ (Markdown):
**âœ… ìœ ì‚¬ì :**
* 
* 

**âŒ ì°¨ì´ì :**
* 
* 
"""
    model = genai.GenerativeModel("gemini-2.5-flash")
    try:
        response = model.generate_content(
            prompt, generation_config=GenerationConfig(temperature=0.2)
        )
        return (response.text or "").strip()
    except Exception as e:
        return f"âŒ Gemini ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë©”ì¸: TF-IDF + ì½”ì‚¬ì¸ â†’ Top3 ì„ ì • â†’ ì‹¬ì¸µ ë¶„ì„ â†’ MD ì €ì¥(í•­ìƒ ìƒì„±)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def analyze_similarity():
    """TF-IDF + ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ Top3 ì„ ì • + ì‹¬ì¸µ ë¶„ì„. ê²°ê³¼ëŠ” analysis_report.md ë¡œ í•­ìƒ ì €ì¥."""
    plan_text, repos_data = load_data()
    if not plan_text or not repos_data:
        # ê·¸ë˜ë„ ë¹ˆ ë ˆí¬íŠ¸ëŠ” ë‚¨ê²¨ ì‚¬ìš©ìì—ê²Œ ì‹ í˜¸ë¥¼ ì£¼ì
        with open("analysis_report.md", "w", encoding="utf-8") as f:
            f.write("# ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨\n\ní•„ìš”í•œ ì…ë ¥ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 0) README ìˆëŠ” ê²ƒë§Œ ì‚¬ìš©
    valid_repos = [r for r in repos_data if (r.get("readme") or "").strip()]
    if not valid_repos:
        with open("analysis_report.md", "w", encoding="utf-8") as f:
            f.write("# ë³´ê³ ì„œ\n\nREADME ê°€ ìˆëŠ” ë¦¬í¬ì§€í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ğŸ”¸ 0-b) ë¶„ì„ ì „ í”„ë¦¬ì»·: ë§¤ì¹­ìˆ˜/ìŠ¤íƒ€ ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ Mê°œë§Œ ë‚¨ê¹€ (ê¸°ë³¸ 60)
    try:
        precut_limit = int(os.getenv("SIM_ANALYZER_PRECUT", "60"))
    except Exception:
        precut_limit = 60
    valid_repos.sort(
        key=lambda x: (-int(x.get("matched_count", 0) or 0), -int(x.get("stars", 0) or 0))
    )
    valid_repos = valid_repos[:precut_limit]

    # 1) TF-IDF ë²¡í„°í™”
    vectorizer = TfidfVectorizer(stop_words="english")
    repo_readmes = [r["readme"] for r in valid_repos]
    all_texts = [plan_text] + repo_readmes
    tfidf_matrix = vectorizer.fit_transform(all_texts)

    # 2) ì½”ì‚¬ì¸ ìœ ì‚¬ë„(ì²« ë²¡í„° vs ë‚˜ë¨¸ì§€)
    cosine_sim = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:])
    for i, r in enumerate(valid_repos):
        r["similarity"] = float(cosine_sim[0][i])

    # 3) ì •ë ¬ í›„ Top 3
    sorted_repos = sorted(valid_repos, key=lambda x: x["similarity"], reverse=True)
    top_3_repos = sorted_repos[:3]

    # 4) ë³´ê³ ì„œ ìƒì„±(í•­ìƒ íŒŒì¼ ìƒì„±)
    report_lines = []

    # --- í„°ë¯¸ë„ ë° íŒŒì¼ í—¤ë” ---
    header = "ğŸ† í”„ë¡œì íŠ¸ ê¸°íšì„œì™€ ê°€ì¥ ìœ ì‚¬í•œ Github ë¦¬í¬ì§€íŠ¸ë¦¬ Top3 ğŸ†"
    print("\n" + "=" * 80)
    print(header)
    print("=" * 80 + "\n")
    report_lines.append(f"# {header}\n")

    if not top_3_repos:
        msg = "ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ë¦¬í¬ì§€í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤."
        print(msg)
        report_lines.append(msg)
    else:
        for i, repo in enumerate(top_3_repos):
            repo_header_info = f"#{i+1}: {repo['name']} (â­{repo.get('stars', 0)})"
            print(repo_header_info)
            print(f"  - URL: {repo['url']}")
            print(f"  - ìœ ì‚¬ë„ ì ìˆ˜: {repo['similarity']:.4f}")

            report_lines.append(f"## {i+1}. {repo['name']} (â­{repo.get('stars', 0)})")
            report_lines.append(f"- **URL**: <{repo['url']}>")
            report_lines.append(f"- **ìœ ì‚¬ë„ ì ìˆ˜**: {repo['similarity']:.4f}")

            # ğŸ”¸ ì‹¬ì¸µ ë¶„ì„ì€ ì‹¤íŒ¨í•˜ë”ë¼ë„ ë³´ê³ ì„œ ì‘ì„±ì„ ê³„ì†
            try:
                analysis_result = analyze_similarity_with_gemini(
                    plan_text, repo.get("readme", ""), repo["name"]
                )
            except Exception as e:
                analysis_result = f"(ì‹¬ì¸µ ë¶„ì„ ì‹¤íŒ¨) {e}"

            indented = "  " + (analysis_result or "").replace("\n", "\n  ")
            print(f"  - ì‹¬ì¸µ ë¶„ì„:\n{indented}\n")
            report_lines.append(f"- **ì‹¬ì¸µ ë¶„ì„**:\n{analysis_result}\n")

    report_filename = "analysis_report.md"
    with open(report_filename, "w", encoding="utf-8") as f:
        f.write("\n".join(report_lines))
    print(f"\nâœ… ë¶„ì„ ë³´ê³ ì„œë¥¼ '{report_filename}' íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    analyze_similarity()
