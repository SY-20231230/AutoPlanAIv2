# -*- coding: utf-8 -*-
import os
import json
from dotenv import load_dotenv
import google.generativeai as genai
from google.generativeai.types import GenerationConfig
import datetime
import glob
from typing import Any, Dict, List

# 1. .envì—ì„œ API Key ë¡œë“œ
load_dotenv()
# API í‚¤ í™˜ê²½ ë³€ìˆ˜ ì´ë¦„ì„ "GOOGLE_API_KEY"ë¡œ í†µì¼í•©ë‹ˆë‹¤.
api_key = os.getenv("GEMINI_API_KEY_1")
if not api_key:
    raise ValueError("GEMINI_API_KEY_1 í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
genai.configure(api_key=api_key)


def make_prompt(plan_text: str, existing_features: list = None) -> str:
    """
    Gemini í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´ë¯¸ ì¶”ì¶œëœ ê¸°ëŠ¥ ëª©ë¡ì„ ë°›ì•„ ì¤‘ë³µì„ ë°©ì§€í•©ë‹ˆë‹¤.
    """
    
    # ì´ì „ì— ì¶”ì¶œëœ ê¸°ëŠ¥ì´ ìˆëŠ” ê²½ìš°, í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€í•˜ì—¬ ì¤‘ë³µì„ ë°©ì§€í•˜ë„ë¡ ëª…ì‹œ
    if existing_features:
        deduplication_instruction = f"""
        ---
        ğŸš¨ **ì¤‘ìš”: ì´ì „ì— ì¶”ì¶œëœ ê¸°ëŠ¥ ëª©ë¡**

        ì•„ë˜ëŠ” ì´ë¯¸ ì¶”ì¶œëœ ê¸°ëŠ¥ ëª©ë¡ì…ë‹ˆë‹¤. ê¸°íšì„œë¥¼ ë‹¤ì‹œ í•œë²ˆ ë©´ë°€íˆ ê²€í† í•˜ì—¬, **ì•„ë˜ ëª©ë¡ì— ì—†ëŠ” ìƒˆë¡œìš´ ê¸°ëŠ¥ë“¤ë§Œ ì¶”ê°€ë¡œ ì¶”ì¶œí•˜ì‹­ì‹œì˜¤.**
        ì´ë¯¸ ìˆëŠ” ê¸°ëŠ¥ê³¼ ëª…ì¹­ì´ë‚˜ ì„¤ëª…ì´ ì¡°ê¸ˆì´ë¼ë„ ë¹„ìŠ·í•˜ë‹¤ë©´ ì ˆëŒ€ ì¤‘ë³µí•´ì„œ ìƒì„±í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤.

        ```json
        {json.dumps(existing_features, indent=2, ensure_ascii=False)}
        ```
        ---
        """
        final_instruction = "ì´ì œ ìœ„ ê¸°íšì„œë¥¼ ë‹¤ì‹œ ë¶„ì„í•´, **ì´ì „ì— ì¶”ì¶œë˜ì§€ ì•Šì€ ìƒˆë¡œìš´ ê¸°ëŠ¥ ëª©ë¡**ì„ ìµœëŒ€í•œ ë§ì´ ìƒì„±í•˜ì‹­ì‹œì˜¤."
    else:
        deduplication_instruction = ""
        final_instruction = "ì´ì œ ìœ„ ê¸°íšì„œë¥¼ ë¶„ì„í•´ ìœ„ JSON êµ¬ì¡°ì— ë”°ë¼ ê¸°ëŠ¥ ëª©ë¡ì„ ìµœëŒ€í•œ ë§ì´ ìƒì„±í•˜ì‹­ì‹œì˜¤."

    return f'''
    ë‹¤ìŒì€ í•œ ê°œì˜ ì†Œí”„íŠ¸ì›¨ì–´/ì„œë¹„ìŠ¤ ê¸°íšì„œì…ë‹ˆë‹¤.  
    ë‹¹ì‹ ì€ ì´ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ì—¬, **ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­ì„ ê°€ëŠ¥í•œ í•œ ë§ì´, êµ¬ì²´ì ìœ¼ë¡œ, ê·¸ë¦¬ê³  ì •í˜•í™”ëœ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œ**í•´ì•¼ í•©ë‹ˆë‹¤.

    ğŸ” **ë‹¹ì‹ ì˜ ì„ë¬´**

    1. ë¬¸ì„œ ì „ì²´ë¥¼ ëê¹Œì§€ ì½ê³ , í•´ë‹¹ ê¸°íšì„œì— í¬í•¨ëœ ê¸°ëŠ¥ì„ ëª¨ë‘ ë¶„ë¦¬í•˜ì—¬ ë‚˜ì—´í•˜ì‹­ì‹œì˜¤.
    2. í•˜ë‚˜ì˜ ê¸°ëŠ¥ ì•ˆì— ì—¬ëŸ¬ ì—­í• ì´ í¬í•¨ë˜ì–´ ìˆë”ë¼ë„, **ë…¼ë¦¬ì ìœ¼ë¡œ ë¶„ë¦¬ ê°€ëŠ¥í•œ ê¸°ëŠ¥ì€ ì „ë¶€ ë…ë¦½ëœ ê¸°ëŠ¥ìœ¼ë¡œ ì •ì˜**í•˜ì‹­ì‹œì˜¤.
    3. ê¸°ëŠ¥ì€ ì•„ë˜ JSON í˜•ì‹ì„ ê·¸ëŒ€ë¡œ ë”°ë¥´ê³ , **ê°€ëŠ¥í•œ ëª¨ë“  í•„ë“œë¥¼ ì±„ìš°ì‹­ì‹œì˜¤.**

    {deduplication_instruction}

    ğŸ§± **ê¸°ëŠ¥ JSON ì¶œë ¥ í˜•ì‹**

    ```json
    {{
      "ê¸°ëŠ¥ID": "FEAT-001",
      "ê¸°ëŠ¥ëª…": "ê¸°ëŠ¥ëª…ì„ ê°„ê²°í•˜ê³  ì§ê´€ì ìœ¼ë¡œ í‘œí˜„",
      "ê¸°ëŠ¥ì„¤ëª…": {{
        "ëª©ì ": "ê¸°ëŠ¥ì´ ìˆ˜í–‰ë˜ëŠ” ì´ìœ ì™€ í•„ìš”ì„±",
        "í•µì‹¬ì—­í• ": "ì‹¤ì œë¡œ ìˆ˜í–‰í•˜ëŠ” ì£¼ëœ ì‘ì—… ë˜ëŠ” ì²˜ë¦¬"
      }},
      "ì‚¬ìš©ìì‹œë‚˜ë¦¬ì˜¤": {{
        "ìƒí™©": "ê¸°ëŠ¥ì´ ì‚¬ìš©ë˜ëŠ” ì‚¬ìš©ì ìƒí™©",
        "í–‰ë™": "ì‚¬ìš©ìì˜ ìƒí˜¸ì‘ìš© ë°©ì‹"
      }},
      "ì…ë ¥ê°’": {{ "í•„ìˆ˜": [], "ì„ íƒ": [], "í˜•ì‹": "" }},
      "ì¶œë ¥ê°’": {{ "ìš”ì•½ì •ë³´": "", "ìƒì„¸ì •ë³´": "" }},
      "ì²˜ë¦¬ë°©ì‹": {{ "ë‹¨ê³„": [], "ì‚¬ìš©ëª¨ë¸": "" }},
      "ì˜ˆì™¸ì¡°ê±´ë°ì²˜ë¦¬": {{ "ì…ë ¥ëˆ„ë½": "", "ì˜¤ë¥˜": "" }},
      "ì˜ì¡´ì„±ë˜ëŠ”ì—°ë™í•­ëª©": [],
      "ê¸°ëŠ¥ìš°ì„ ìˆœìœ„": "ë†’ìŒ / ì¤‘ê°„ / ë‚®ìŒ",
      "UIìš”ì†Œ": [],
      "í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ì˜ˆì‹œ": []
    }}
    ```
    ğŸ“Œ ì£¼ì˜ì‚¬í•­:
    - **ê¸°ëŠ¥ì˜ ìˆ˜ì—ëŠ” ì œí•œì´ ì—†ìŠµë‹ˆë‹¤. ê¸°íšì„œì— ëª…ì‹œì ì´ê±°ë‚˜ ì•”ì‹œëœ ëª¨ë“  ê¸°ëŠ¥ì„ ìµœëŒ€í•œ ë§ì´ ì°¾ì•„ì„œ í¬í•¨í•˜ì‹­ì‹œì˜¤.**
    - ì˜¤ì§ JSON ë°°ì—´(ë¦¬ìŠ¤íŠ¸)ë¡œë§Œ ì¶œë ¥í•´ì•¼ í•˜ë©°, ë‹¤ë¥¸ ì„¤ëª…ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.

    ---
    ğŸ“„ **ê¸°íšì„œ ì›ë¬¸**

    """
    {plan_text}
    """

    {final_instruction}
    **ì˜¤ì§ JSON ë°°ì—´ë¡œë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤. ë‹¤ë¥¸ ì„¤ëª…ì€ ì¶œë ¥í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.**
    '''

def generate_feature_list(plan_text: str, existing_features: list = None):
    """
    Geminië¥¼ í˜¸ì¶œí•˜ì—¬ ê¸°ëŠ¥ ëª©ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    prompt = make_prompt(plan_text, existing_features)
    model = genai.GenerativeModel("gemini-1.5-flash") # 1.5-flashê°€ ê¸´ ì»¨í…ìŠ¤íŠ¸ ì²˜ë¦¬ì— ë” ìœ ë¦¬í•  ìˆ˜ ìˆìŒ
    response = model.generate_content(prompt, generation_config=GenerationConfig(temperature=0.1))

    raw = response.text.strip()
    # ì‘ë‹µì´ ë¹„ì–´ìˆëŠ” ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    if not raw:
        return []

    raw = raw.replace("```json", "").replace("```", "").strip()

    try:
        data = json.loads(raw)
        if isinstance(data, list):
            return data
        else:
            print("âŒ ì˜ˆìƒê³¼ ë‹¤ë¥¸ êµ¬ì¡°(ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹˜):", type(data))
            return []
    except Exception as e:
        print("âŒ JSON íŒŒì‹± ì‹¤íŒ¨:", e)
        print("ğŸ” ì›ë³¸ ì¶œë ¥:\n", raw)
        return []

def _safe_get(mapping: Dict[str, Any], key: str, default: Any = "") -> Any:
    return mapping.get(key, default) if isinstance(mapping, dict) else default

def _to_text(value: Any) -> str:
    if value is None:
        return ""
    if isinstance(value, str):
        return value
    if isinstance(value, (int, float)):
        return str(value)
    if isinstance(value, list):
        normalized: List[str] = []
        for item in value:
            if isinstance(item, (str, int, float)):
                normalized.append(str(item))
            else:
                try:
                    normalized.append(json.dumps(item, ensure_ascii=False))
                except Exception:
                    normalized.append(str(item))
        return ", ".join(normalized)
    if isinstance(value, dict):
        try:
            return json.dumps(value, ensure_ascii=False)
        except Exception:
            return str(value)
    return str(value)

def flatten_feature_to_row(feature: Dict[str, Any]) -> Dict[str, str]:
    """ê¸°ëŠ¥ JSON í•œ ê±´ì„ í‘œ í˜•íƒœì˜ í•œ í–‰ìœ¼ë¡œ í‰íƒ„í™”í•©ë‹ˆë‹¤."""
    desc = _safe_get(feature, "ê¸°ëŠ¥ì„¤ëª…", {})
    scenario = _safe_get(feature, "ì‚¬ìš©ìì‹œë‚˜ë¦¬ì˜¤", {})
    inputs = _safe_get(feature, "ì…ë ¥ê°’", {})
    outputs = _safe_get(feature, "ì¶œë ¥ê°’", {})
    process = _safe_get(feature, "ì²˜ë¦¬ë°©ì‹", {})
    exceptions = _safe_get(feature, "ì˜ˆì™¸ì¡°ê±´ë°ì²˜ë¦¬", {})

    row: Dict[str, str] = {
        "ê¸°ëŠ¥ID": _to_text(_safe_get(feature, "ê¸°ëŠ¥ID", "")),
        "ê¸°ëŠ¥ëª…": _to_text(_safe_get(feature, "ê¸°ëŠ¥ëª…", "")),
        "ëª©ì ": _to_text(_safe_get(desc, "ëª©ì ", "")),
        "í•µì‹¬ì—­í• ": _to_text(_safe_get(desc, "í•µì‹¬ì—­í• ", "")),
        "ìƒí™©": _to_text(_safe_get(scenario, "ìƒí™©", "")),
        "í–‰ë™": _to_text(_safe_get(scenario, "í–‰ë™", "")),
        "ì…ë ¥ê°’_í•„ìˆ˜": _to_text(_safe_get(inputs, "í•„ìˆ˜", [])),
        "ì…ë ¥ê°’_ì„ íƒ": _to_text(_safe_get(inputs, "ì„ íƒ", [])),
        "ì…ë ¥ê°’_í˜•ì‹": _to_text(_safe_get(inputs, "í˜•ì‹", "")),
        "ì¶œë ¥ê°’_ìš”ì•½ì •ë³´": _to_text(_safe_get(outputs, "ìš”ì•½ì •ë³´", "")),
        "ì¶œë ¥ê°’_ìƒì„¸ì •ë³´": _to_text(_safe_get(outputs, "ìƒì„¸ì •ë³´", "")),
        "ì²˜ë¦¬ë‹¨ê³„": _to_text(_safe_get(process, "ë‹¨ê³„", [])),
        "ì‚¬ìš©ëª¨ë¸": _to_text(_safe_get(process, "ì‚¬ìš©ëª¨ë¸", "")),
        "ì˜ˆì™¸_ì…ë ¥ëˆ„ë½": _to_text(_safe_get(exceptions, "ì…ë ¥ëˆ„ë½", "")),
        "ì˜ˆì™¸_ì˜¤ë¥˜": _to_text(_safe_get(exceptions, "ì˜¤ë¥˜", "")),
        "ì˜ì¡´ì„±": _to_text(_safe_get(feature, "ì˜ì¡´ì„±ë˜ëŠ”ì—°ë™í•­ëª©", [])),
        "ê¸°ëŠ¥ìš°ì„ ìˆœìœ„": _to_text(_safe_get(feature, "ê¸°ëŠ¥ìš°ì„ ìˆœìœ„", "")),
        "UIìš”ì†Œ": _to_text(_safe_get(feature, "UIìš”ì†Œ", [])),
        "í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ì˜ˆì‹œ": _to_text(_safe_get(feature, "í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ì˜ˆì‹œ", [])),
    }
    return row

def export_tabular_files(plan_lines: List[str], features: List[Dict[str, Any]], filename_base: str) -> None:
    """ë‹¨ì¼ ì—‘ì…€ íŒŒì¼(xlsx)ë¡œ ë‚´ë³´ëƒ…ë‹ˆë‹¤.

    - ì‹œíŠ¸ 'ê¸°ëŠ¥ëª©ë¡': ì „ì²´ í•„ë“œ(ì •ê·œ ìŠ¤í‚¤ë§ˆ)
    - ì‹œíŠ¸ 'ê°€ë…ìš”ì•½': ìš”ì•½ í‘œ(ê°€ë…ì„± ì¤‘ì‹¬)
    - ì‹œíŠ¸ 'ê¸°íšì„œì›ë¬¸': ì›ë¬¸ ë¼ì¸
    """
    try:
        import pandas as pd  # type: ignore
        from openpyxl.styles import Alignment, Font, PatternFill
        from openpyxl.utils import get_column_letter

        # ì „ì²´ í•„ë“œ í–‰ êµ¬ì„±
        full_rows = [flatten_feature_to_row(f) for f in features]
        full_headers = [
            "ê¸°ëŠ¥ID",
            "ê¸°ëŠ¥ëª…",
            "ëª©ì ",
            "í•µì‹¬ì—­í• ",
            "ìƒí™©",
            "í–‰ë™",
            "ì…ë ¥ê°’_í•„ìˆ˜",
            "ì…ë ¥ê°’_ì„ íƒ",
            "ì…ë ¥ê°’_í˜•ì‹",
            "ì¶œë ¥ê°’_ìš”ì•½ì •ë³´",
            "ì¶œë ¥ê°’_ìƒì„¸ì •ë³´",
            "ì²˜ë¦¬ë‹¨ê³„",
            "ì‚¬ìš©ëª¨ë¸",
            "ì˜ˆì™¸_ì…ë ¥ëˆ„ë½",
            "ì˜ˆì™¸_ì˜¤ë¥˜",
            "ì˜ì¡´ì„±",
            "ê¸°ëŠ¥ìš°ì„ ìˆœìœ„",
            "UIìš”ì†Œ",
            "í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ì˜ˆì‹œ",
        ]

        # ìš”ì•½ í‘œ í–‰ êµ¬ì„±
        compact_rows = [_compact_row(f) for f in features]
        compact_headers = [
            "ì£¼ìš” ê¸°ëŠ¥",
            "í˜ì´ì§€",
            "ì—…ë¬´ ëŒ€ë¶„ë¥˜",
            "ì—…ë¬´ ì¤‘ë¶„ë¥˜",
            "ì—…ë¬´ ì†Œë¶„ë¥˜",
            "ì—­í• ",
            "ì½”ë©˜íŠ¸",
        ]

        xlsx_filename = f"{filename_base}.xlsx"
        with pd.ExcelWriter(xlsx_filename, engine="openpyxl") as writer:
            # ê¸°ëŠ¥ëª©ë¡
            pd.DataFrame(full_rows, columns=full_headers).to_excel(
                writer, index=False, sheet_name="ê¸°ëŠ¥ëª©ë¡"
            )
            # ê°€ë…ìš”ì•½
            pd.DataFrame(compact_rows, columns=compact_headers).to_excel(
                writer, index=False, sheet_name="ê°€ë…ìš”ì•½"
            )
            # ê¸°íšì„œì›ë¬¸
            pd.DataFrame({"ê¸°íšì„œì›ë¬¸": plan_lines}).to_excel(
                writer, index=False, sheet_name="ê¸°íšì„œì›ë¬¸"
            )

            # ì„œì‹ ì ìš©
            for sheet_name in ["ê¸°ëŠ¥ëª©ë¡", "ê°€ë…ìš”ì•½"]:
                ws = writer.sheets[sheet_name]
                ws.freeze_panes = "A2"
                ws.auto_filter.ref = ws.dimensions
                # í—¤ë” ìŠ¤íƒ€ì¼
                header_fill = PatternFill(start_color="FFE2E8F0", end_color="FFE2E8F0", fill_type="solid")
                for cell in ws[1]:
                    cell.font = Font(bold=True)
                    cell.fill = header_fill
                    cell.alignment = Alignment(wrap_text=True, vertical="center")
                # ë³¸ë¬¸ ì •ë ¬ ë° ìë™ ë„ˆë¹„
                max_lengths: Dict[int, int] = {}
                for row in ws.iter_rows(min_row=2, max_row=ws.max_row, min_col=1, max_col=ws.max_column):
                    for idx, cell in enumerate(row, start=1):
                        text = "" if cell.value is None else str(cell.value)
                        max_lengths[idx] = max(max_lengths.get(idx, 0), len(text))
                        cell.alignment = Alignment(wrap_text=True, vertical="top")
                for col_idx, max_len in max_lengths.items():
                    col_letter = get_column_letter(col_idx)
                    ws.column_dimensions[col_letter].width = min(max(12, max_len + 2), 80)

        print(f"ğŸ“Š ì—‘ì…€ íŒŒì¼ì´ '{xlsx_filename}'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except ImportError:
        print("â„¹ï¸ pandas/openpyxlì´ ì—†ì–´ XLSX ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤. 'pip install pandas openpyxl' ì‹¤í–‰ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
    except Exception as e:
        print("âŒ XLSX ì €ì¥ ì‹¤íŒ¨:", e)

def _compact_row(feature: Dict[str, Any]) -> Dict[str, str]:
    """ì´ë¯¸ì§€ ì˜ˆì‹œ í˜•íƒœ(ê°€ë…ì„± í‘œ)ì— ë§ì¶˜ ìš”ì•½ í–‰ ë§¤í•‘."""
    desc = _safe_get(feature, "ê¸°ëŠ¥ì„¤ëª…", {})
    scenario = _safe_get(feature, "ì‚¬ìš©ìì‹œë‚˜ë¦¬ì˜¤", {})

    # í˜ì´ì§€ëŠ” UIìš”ì†Œê°€ ìˆìœ¼ë©´ ì²« í•­ëª©, ì—†ìœ¼ë©´ 'ìƒí™©'ì„ ëŒ€ì²´ ì‚¬ìš©
    page_candidates = _safe_get(feature, "UIìš”ì†Œ", [])
    page = ""
    if isinstance(page_candidates, list) and page_candidates:
        page = _to_text(page_candidates[0])
    elif _safe_get(scenario, "ìƒí™©"):
        page = _to_text(_safe_get(scenario, "ìƒí™©"))

    row = {
        "ì£¼ìš” ê¸°ëŠ¥": _to_text(_safe_get(feature, "ê¸°ëŠ¥ëª…", "")),
        "í˜ì´ì§€": page,
        "ì—…ë¬´ ëŒ€ë¶„ë¥˜": _to_text(_safe_get(scenario, "ìƒí™©", "")),
        "ì—…ë¬´ ì¤‘ë¶„ë¥˜": _to_text(_safe_get(desc, "ëª©ì ", "")),
        "ì—…ë¬´ ì†Œë¶„ë¥˜": _to_text(_safe_get(scenario, "í–‰ë™", "")),
        "ì—­í• ": _to_text(_safe_get(desc, "í•µì‹¬ì—­í• ", "")),
        "ì½”ë©˜íŠ¸": _to_text(_safe_get(_safe_get(feature, "ì¶œë ¥ê°’", {}), "ìš”ì•½ì •ë³´", "")),
    }
    return row

# (ìš”ì•½ ì „ìš© ê°œë³„ íŒŒì¼ ë‚´ë³´ë‚´ê¸° í•¨ìˆ˜ëŠ” ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤)

if __name__ == "__main__":
    print("âœï¸ ê¸°íšì„œë¥¼ ì…ë ¥í•˜ì„¸ìš” (Enter ë‘ ë²ˆìœ¼ë¡œ ì¢…ë£Œ):")
    lines = []
    while True:
        line = input()
        if line.strip() == "":
            break
        lines.append(line)
    plan_text = "\n".join(lines)

    if not plan_text:
        print("ì…ë ¥ëœ ë‚´ìš©ì´ ì—†ì–´ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    else:
        final_features: List[Dict[str, Any]] = []
        MAX_PASSES = int(os.getenv("AUTO_PASSES", "5"))
        for pass_count in range(1, MAX_PASSES + 1):
            print("\n" + "="*50)
            print(f"ğŸ” ìë™ ì‹¤í–‰: ê¸°ëŠ¥ ì¶”ì¶œ íŒ¨ìŠ¤ #{pass_count} ì§„í–‰")

            new_features = generate_feature_list(plan_text, existing_features=final_features)
            if new_features:
                start_id = len(final_features) + 1
                for i, feature in enumerate(new_features):
                    feature['ê¸°ëŠ¥ID'] = f"FEAT-{start_id+i:03d}"
                final_features.extend(new_features)
                print(f"âœ… {len(new_features)}ê°œ ì¶”ê°€ â†’ ëˆ„ì  {len(final_features)}ê°œ")
            else:
                print("âœ… ë” ì´ìƒ ìƒˆë¡œìš´ ê¸°ëŠ¥ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìë™ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break

        # ìµœì¢… ê²°ê³¼ ì €ì¥
        print("\n" + "="*50)
        print(f"ì´ {len(final_features)}ê°œì˜ ê¸°ëŠ¥ìœ¼ë¡œ ìµœì¢… ëª…ì„¸ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
        
        existing_files = glob.glob("features_*.json")
        existing_nums = [int(f.split("_")[1].split(".")[0]) for f in existing_files if f.startswith("features_") and f.split("_")[1].split(".")[0].isdigit()]
        next_index = max(existing_nums) + 1 if existing_nums else 1
        filename = f"features_{next_index}.json"

        plan_lines = plan_text.splitlines()
        output_data = {
            "ê¸°íšì„œì›ë¬¸": plan_lines,
            "ê¸°ëŠ¥ëª©ë¡": final_features
        }

        try:
            with open(filename, "w", encoding="utf-8") as f:
                json.dump(output_data, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ ìµœì¢… ê¸°ëŠ¥ ëª…ì„¸ì„œê°€ '{filename}' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print("âŒ JSON ì €ì¥ ì‹¤íŒ¨:", e)
        
        # CSV / XLSXë¡œë„ ë‚´ë³´ë‚´ê¸°
        base = filename.rsplit(".", 1)[0]
        export_tabular_files(plan_lines, final_features, base)
