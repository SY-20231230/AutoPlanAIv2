#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Auto Document Writer â€” Interactive + Batch (Gemini 2.5-Flash)
- DOCX/HWPX: {{í‚¤}}ê°€ ìˆìœ¼ë©´ ì¹˜í™˜ ëª¨ë“œ, ì—†ìœ¼ë©´ êµ¬ì¡°-ëª¨ë°© ëª¨ë“œ(Markdown)
- PDF/HWP : êµ¬ì¡°-ëª¨ë°© ëª¨ë“œ(Markdown)
ê°œì„  í¬ì¸íŠ¸:
  * [ì™„ë£Œ] íœ´ë¦¬ìŠ¤í‹± ì‹¤íŒ¨ ì‹œ, LLMì„ ì´ìš©í•œ ë™ì  êµ¬ì¡° ë¶„ì„ ê¸°ëŠ¥ ì¶”ê°€
  * ì•ˆì „í•œ LLM í˜¸ì¶œ(ì„¸ì´í”„í‹° ì™„í™”, ë¬´ì‘ë‹µ í´ë°±, ì¬ì‹œë„)
  * í—¤ë”©ì„ ë°°ì¹˜ë¡œ ë¶„í• í•˜ì—¬ ì„¹ì…˜ ìƒì„±(ëŒ€ìš©ëŸ‰ í…œí”Œë¦¿ ì•ˆì •í™”)
  * PDF ê¸´ í…ìŠ¤íŠ¸ íŠ¸ë¦¼(ìµœëŒ€ 50KB)
  * ë°°ì¹˜ë³„ ì¤‘ê°„ ê²°ê³¼ ì €ì¥ + ìµœì¢… í•©ë³¸ ì €ì¥
ì„¤ì¹˜:
  pip install google-generativeai python-docx python-dotenv pymupdf
.env:
  GEMINI_API_KEY=YOUR_KEY
"""

import os
import re
import sys
import json
import zipfile
from pathlib import Path
from typing import Dict, List, Tuple, Optional

from dotenv import load_dotenv
import google.generativeai as genai

# ---- Optional imports ----
try:
    import fitz  # PyMuPDF for PDF
except Exception:
    fitz = None

try:
    from docx import Document as DocxDocument
    from docx.shared import RGBColor
except Exception:
    DocxDocument = None

# --------------------------
# Gemini ì´ˆê¸°í™”
# --------------------------
def init_gemini(model_name: str):
    load_dotenv()
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise RuntimeError("GEMINI_API_KEY ê°€ .env ì— ì—†ìŠµë‹ˆë‹¤.")
    genai.configure(api_key=api_key)
    return genai.GenerativeModel(model_name)

# --------------------------
# ìœ í‹¸: íŒŒì¼/ë¬¸ì„œ ë„ìš°ë¯¸
# --------------------------
PLACEHOLDER_PATTERN = re.compile(r"\{\{([^{}]+)\}\}")

def read_json_or_text(p: Path) -> str:
    raw = p.read_text(encoding="utf-8", errors="ignore")
    try:
        obj = json.loads(raw)
        return json.dumps(obj, ensure_ascii=False, indent=2)
    except Exception:
        return raw

def detect_placeholders_in_text(text: str) -> List[str]:
    return sorted(set(m.group(1).strip() for m in PLACEHOLDER_PATTERN.finditer(text)))

def extract_text_from_pdf(p: Path, max_bytes: int = 50000) -> str:
    if fitz is None:
        return "(PyMuPDF ë¯¸ì„¤ì¹˜) PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ë¶ˆê°€"
    doc = fitz.open(p.as_posix())
    pages = []
    total = 0
    for i, page in enumerate(doc, start=1):
        if total >= max_bytes:
            break
        try:
            t = page.get_text("text")
        except Exception:
            t = "(í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨)"
        chunk = f"# Page {i}\n{t}"
        pages.append(chunk)
        total += len(chunk.encode("utf-8", errors="ignore"))
    doc.close()
    return "\n\n".join(pages)

def load_docx_and_plaintext(p: Path) -> Tuple[Optional[object], str]:
    if DocxDocument is None:
        return None, ""
    doc = DocxDocument(p.as_posix())
    texts = []
    for para in doc.paragraphs:
        texts.append(para.text)
    for table in doc.tables:
        for row in table.rows:
            texts.append("\t".join(cell.text for cell in row.cells))
    return doc, "\n".join(texts)

def hwpx_read_xml(p: Path) -> Tuple[bytes, List[str]]:
    with zipfile.ZipFile(p, 'r') as z:
        texts = []
        for name in z.namelist():
            if name.lower().endswith(".xml"):
                with z.open(name) as f:
                    try:
                        data = f.read()
                        texts.append(data.decode("utf-8", errors="ignore"))
                    except Exception:
                        pass
        full = "\n".join(texts)
        placeholders = detect_placeholders_in_text(full)
        return full.encode("utf-8"), placeholders

def hwpx_replace_and_write(src: Path, dst: Path, mapping: Dict[str, str], unsure_to_red=True):
    # ê°„ë‹¨ ì „ì—­ì¹˜í™˜ ë°©ì‹(ì‹¤ì „ì€ XML ìŠ¤íƒ€ì¼ í¸ì§‘ ê¶Œì¥)
    with zipfile.ZipFile(src, 'r') as zin:
        with zipfile.ZipFile(dst, 'w', zipfile.ZIP_DEFLATED) as zout:
            for item in zin.infolist():
                data = zin.read(item.filename)
                if item.filename.lower().endswith(".xml"):
                    text = data.decode("utf-8", errors="ignore")
                    if unsure_to_red:
                        text = re.sub(r"<<UNSURE:(.+?))>>?", r"(ë¶ˆí™•ì‹¤: \1)", text)
                    for k, v in mapping.items():
                        text = text.replace(f"{{{{{k}}}}}", v)
                    data = text.encode("utf-8")
                zout.writestr(item, data)

def docx_replace_placeholders(doc, mapping: Dict[str, str], unsure_to_red=True):
    def replace_run_text(run, key, value):
        if f"{{{{{key}}}}}" in run.text:
            run.text = run.text.replace(f"{{{{{key}}}}}", value)

    for para in doc.paragraphs:
        for key, value in mapping.items():
            for run in para.runs:
                replace_run_text(run, key, value)
        if unsure_to_red and "<<UNSURE:" in para.text:
            for run in para.runs:
                m = re.search(r"<<UNSURE:(.+?))>>?", run.text)
                if m:
                    run.text = run.text.replace(m.group(0), m.group(1))
                    run.font.color.rgb = RGBColor(0xFF, 0x00, 0x00)

    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                for key, value in mapping.items():
                    cell.text = cell.text.replace(f"{{{{{key}}}}}", value)
                if unsure_to_red and "<<UNSURE:" in cell.text:
                    cell.text = cell.text.replace("<<UNSURE:", "(ë¶ˆí™•ì‹¤: ").replace(">>", ")")

# --- MODIFIED FUNCTION ---
# 1. íœ´ë¦¬ìŠ¤í‹±(ê·œì¹™ ê¸°ë°˜) ì œëª© ì¶”ì¶œ í•¨ìˆ˜ ê°œì„ 
#    - ë” ë‹¤ì–‘í•œ íŒ¨í„´ì„ ê°ì§€í•˜ë„ë¡ ì •ê·œì‹ í™•ì¥
#    - ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì • (í•˜ë“œì½”ë”©ëœ ëª©ë¡ ì œê±°)
def extract_headings_heuristic(raw_text: str) -> List[str]:
    """ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ë¬¸ì„œì—ì„œ ì œëª©/í•­ëª©ì„ ì¶”ì¶œí•©ë‹ˆë‹¤. ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    lines = [ln.strip() for ln in raw_text.splitlines() if ln.strip()]
    headings = []
    # ë” ë§ì€ ì œëª© íŒ¨í„´ ê°ì§€ (ì˜ˆ: "1.", "ê°€.", "â– ", "[1]", "ì œëª©:")
    pat = re.compile(
        r"^(\d+(\.\d+)*|[IVXLCM]+\.|[ê°€-í£A-Z]\.|ì œ?\d+ì¥|â– |â—|â–¡|â—‹|[\(]?\d+[\)]?)\s+|.*:$"
    )
    for ln in lines:
        # 80ì ì´í•˜ì˜ ì§§ì€ ì¤„ì´ë©´ì„œ, íŒ¨í„´ì— ë§ê±°ë‚˜ ì½œë¡ (:)ìœ¼ë¡œ ëë‚˜ëŠ” ê²½ìš°
        if len(ln) <= 80 and pat.search(ln):
            # "Page X" ê°™ì€ PDF ì¶”ì¶œ ì•„í‹°íŒ©íŠ¸ ì œê±°
            if not ln.startswith("# Page"):
                headings.append(ln)

    seen, ordered = set(), []
    for h in headings:
        if h not in seen:
            seen.add(h); ordered.append(h)
    
    # ìƒìœ„ 60ê°œê¹Œì§€ë§Œ ì‚¬ìš©í•˜ê³ , ì°¾ì§€ ëª»í•˜ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    return ordered[:60]

# --- NEW FUNCTION ---
# 2. LLMì„ ì´ìš©í•œ ë¬¸ì„œ êµ¬ì¡°(ì œëª©) ì¶”ì¶œ í•¨ìˆ˜
def extract_structure_with_llm(model, raw_text: str) -> List[str]:
    """íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ ì œëª© ì°¾ê¸° ì‹¤íŒ¨ ì‹œ, LLMì„ ì‚¬ìš©í•´ ë¬¸ì„œ êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ê³  ì œëª© ëª©ë¡ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    prompt = f"""
ë‹¤ìŒì€ íŠ¹ì • ì–‘ì‹ì—ì„œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì´ ë¬¸ì„œì˜ í•µì‹¬ì ì¸ ëª©ì°¨, í—¤ë”©, ë˜ëŠ” ì‘ì„±í•´ì•¼ í•  í•­ëª©ë“¤ì„ ìˆœì„œëŒ€ë¡œ ë‚˜ì—´í•´ì£¼ì„¸ìš”.
- ê° í•­ëª©ì€ í•œ ì¤„ì— í•˜ë‚˜ì”©ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
- ë¶ˆí•„ìš”í•œ ì„¤ëª…ì´ë‚˜ ë²ˆí˜¸ ë§¤ê¸°ê¸°ëŠ” ìƒëµí•˜ê³ , í…ìŠ¤íŠ¸ì— ë‚˜íƒ€ë‚œ ì œëª©ì´ë‚˜ í•­ëª©ëª… ìì²´ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.
- ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í•­ëª©ì„ ë§Œë“¤ì§€ ë§ˆì„¸ìš”.
- ë§Œì•½ ë¶„ì„ì´ ë¶ˆê°€ëŠ¥í•˜ë©´, "êµ¬ì¡°ë¶„ì„ë¶ˆê°€" ë¼ê³ ë§Œ ì¶œë ¥í•˜ì„¸ìš”.

[ë¬¸ì„œ í…ìŠ¤íŠ¸]
{raw_text[:10000]}
"""
    try:
        resp = model.generate_content(prompt)
        text = resp.text.strip()
        if "êµ¬ì¡°ë¶„ì„ë¶ˆê°€" in text or not text:
            return []
        # LLM ì‘ë‹µì—ì„œ ë¶ˆí•„ìš”í•œ ë¶€ë¶„ì„ ì œê±°í•˜ê³  ê¹”ë”í•œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        headings = [line.strip() for line in text.splitlines() if line.strip()]
        # ê°€ë” LLMì´ ë¶™ì´ëŠ” '-', '*' ê°™ì€ ë§ˆì»¤ ì œê±°
        return [re.sub(r"^[-\*]\s+", "", h) for h in headings if h]
    except Exception as e:
        print(f"[ê²½ê³ ] LLM êµ¬ì¡° ë¶„ì„ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}", file=sys.stderr)
        return []

# --------------------------
# í”„ë¡¬í”„íŠ¸ ë¹Œë”
# --------------------------
def build_prompt(plan_text: str,
                 feature_json_text: Optional[str],
                 task_desc: str,
                 tone: str,
                 style: str,
                 leave_blanks: bool,
                 max_bullets: int = 6,
                 max_chars_per_field: int = 800) -> str:
    rules = f"""
ë‹¹ì‹ ì€ ì •ë¶€/ê³µëª¨/ì—°êµ¬ê°œë°œ ì–‘ì‹ì— ë§ì¶° ë¬¸ì„œë¥¼ ì‘ì„±í•˜ëŠ” ì „ë¬¸ ë³´ì¡°ìì…ë‹ˆë‹¤.

[ë¬¸ì„œ ê·œì¹™]
- ì–´íˆ¬/í†¤: {tone}
- ë¬¸ì¥ ìŠ¤íƒ€ì¼: {style} (ë¶ˆë¦¿ì´ë©´ ìµœëŒ€ {max_bullets}ê°œ, í•­ëª©ë‹¹ 1~2ë¬¸ì¥)
- í•„ë“œ/ì„¹ì…˜ë‹¹ ìµœëŒ€ {max_chars_per_field}ì ì´ë‚´ë¡œ ìš”ì•½
- ê³¼ì¥ ê¸ˆì§€, ì‚¬ì‹¤ ê¸°ë°˜ í‘œí˜„. ëª¨í˜¸í•˜ë©´ ì¶”ì •í•˜ì§€ ë§ˆì„¸ìš”.
- ë¶ˆí™•ì‹¤/ì •ë³´ë¶€ì¡±: {"ë¹ˆì¹¸ìœ¼ë¡œ ë‚¨ê²¨ë‘ì„¸ìš”" if leave_blanks else "ë‹¤ìŒ í† í°ìœ¼ë¡œ í‘œì‹œ: <<UNSURE: ê°„ë‹¨ ì‚¬ìœ /ì§ˆë¬¸ >>"}
- ê°œì¸ì •ë³´/í—ˆìœ„ ê¸°ì¬ ê¸ˆì§€
- ìˆ«ì/ì§€í‘œ/ê·¼ê±°ëŠ” ê°€ëŠ¥í•˜ë©´ êµ¬ì²´í™”(ì—†ìœ¼ë©´ ìƒëµ)

[ì°¸ì¡° ê¸°íšì„œ/ê¸°ëŠ¥ëª…ì„¸]
{plan_text}
"""
    if feature_json_text:
        rules += f"\n[ì¶”ê°€ ê¸°ëŠ¥ ëª…ì„¸(JSON)]\n{feature_json_text}\n"
    if task_desc:
        rules += f"\n[ì‘ì—… ì„¤ëª…]\n{task_desc}\n"
    return rules.strip()
# --------------------------
# í”„ë¡¬í”„íŠ¸ & LLM í˜¸ì¶œ(ì•ˆì „)
# --------------------------
def llm_generate(model, prompt: str, instruction: str) -> str:
    full = prompt + "\n\n[ì‘ì„± ìš”ì²­]\n" + instruction
    gen_cfg = genai.types.GenerationConfig(
        temperature=0.3, top_p=0.9, max_output_tokens=1536
    )

    # âœ… ë²„ì „ í˜¸í™˜: dict í˜•íƒœì˜ safety_settings ì‚¬ìš©
    safety_settings = [
        {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_SEXUAL", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
    ]

    try:
        resp = model.generate_content(
            full,
            generation_config=gen_cfg,
            safety_settings=safety_settings,
        )
        if getattr(resp, "text", None):
            return resp.text.strip()

        # í´ë°±: candidates â†’ parts í…ìŠ¤íŠ¸ í•©ì¹˜ê¸°
        for cand in getattr(resp, "candidates", []) or []:
            parts = getattr(getattr(cand, "content", None), "parts", None)
            if parts:
                joined = "".join(getattr(p, "text", "") for p in parts if getattr(p, "text", ""))
                if joined.strip():
                    return joined.strip()

        # ì§§ê²Œ ì¬ì‹œë„
        resp2 = model.generate_content(
            full[:6000] + "\n\n(ê°„ê²°íˆ 6ì¤„ ì´ë‚´ë¡œ.)",
            generation_config=gen_cfg,
            safety_settings=safety_settings,
        )
        if getattr(resp2, "text", None):
            return resp2.text.strip()

    except Exception as e:
        print(f"[ê²½ê³ ] LLM í˜¸ì¶œ ì˜ˆì™¸: {e}", file=sys.stderr)

    return ""


# --------------------------
# ì¹˜í™˜ ëª¨ë“œ
# --------------------------
def fill_placeholders_with_llm(model,
                               keys: List[str],
                               plan_text: str,
                               feature_json_text: Optional[str],
                               tone: str,
                               style: str,
                               leave_blanks: bool) -> Dict[str, str]:
    mapping = {}
    base_prompt = build_prompt(
        plan_text, feature_json_text,
        "í”Œë ˆì´ìŠ¤í™€ë” í•­ëª©ë³„ë¡œ ê°„ê²°íˆ ì‘ì„±í•˜ì„¸ìš”.",
        tone, style, leave_blanks
    )
    for k in keys:
        instruction = f"""ë‹¤ìŒ í•„ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”.

[í•„ë“œëª…]
{k}

[ì¶œë ¥ í˜•ì‹]
- ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ.
- {("ë¹ˆì¹¸ í—ˆìš©" if leave_blanks else "ë¶ˆí™•ì‹¤í•˜ë©´ <<UNSURE: ...>> ë¡œ í‘œì‹œ")}
"""
        txt = llm_generate(model, base_prompt, instruction)
        if leave_blanks and (txt.strip().lower() in {"n/a", "ì—†ìŒ", "ë¶ˆëª…", "ë¯¸ìƒ"} or "unsure" in txt.lower()):
            txt = ""
        mapping[k] = txt
    return mapping

# --------------------------
# êµ¬ì¡°-ëª¨ë°© ëª¨ë“œ (ë°°ì¹˜)
# --------------------------
def chunk_list(items: List[str], size: int) -> List[List[str]]:
    return [items[i:i+size] for i in range(0, len(items), size)]

def mimic_structure_with_llm_batch(model,
                                   headings: List[str],
                                   plan_text: str,
                                   feature_json_text: Optional[str],
                                   tone: str,
                                   style: str,
                                   leave_blanks: bool,
                                   batch_size: int,
                                   stem_for_save: Path) -> str:
    """í—¤ë”©ì„ batch_sizeë¡œ ë‚˜ëˆ  ì„¹ì…˜ ìƒì„±, ë°°ì¹˜ë³„ ì¤‘ê°„íŒŒì¼ ì €ì¥, ì „ì²´ í•©ë³¸ ë°˜í™˜."""
    base_prompt = build_prompt(
        plan_text, feature_json_text,
        "ë¬¸ì„œì˜ ê° ì„¹ì…˜ì„ í•´ë‹¹ í—¤ë”© ì•„ë˜ì— ì‘ì„±í•˜ì„¸ìš”.",
        tone, style, leave_blanks
    )
    all_sections: List[str] = []
    batches = chunk_list(headings, max(1, batch_size))
    for bi, batch in enumerate(batches, start=1):
        print(f"  - ë°°ì¹˜ {bi}/{len(batches)} (í—¤ë”© {len(batch)}ê°œ) ìƒì„± ì¤‘...")
        batch_blocks = []
        for h in batch:
            instruction = f"""ì•„ë˜ í—¤ë”© ì„¹ì…˜ì„ ì‘ì„±í•˜ì„¸ìš”.

[í—¤ë”©]
{h}

[ì¶œë ¥ í˜•ì‹]
- Markdown ì„¹ì…˜ìœ¼ë¡œ ì¶œë ¥ (ì˜ˆ: '## {h}')
- ë³¸ë¬¸ì€ {style} ê¸°ì¤€
- {("ë¹ˆì¹¸ í—ˆìš©" if leave_blanks else "ë¶ˆí™•ì‹¤ì‹œ <<UNSURE: ...>>")}
"""
            out = llm_generate(model, base_prompt, instruction)
            if not out.strip():
                continue  # ë¹ˆ ì‘ë‹µì€ ìŠ¤í‚µ
            if not out.strip().startswith("#"):
                out = f"## {h}\n\n{out}"
            batch_blocks.append(out)
            all_sections.append(out)

        # ë°°ì¹˜ë³„ ì¤‘ê°„ ì €ì¥
        if batch_blocks:
            md_part = "\n\n".join(batch_blocks)
            part_path = stem_for_save.with_name(f"{stem_for_save.stem}_draft_part{bi}.md")
            part_path.write_text(md_part, encoding="utf-8")
            print(f"    Â· ì €ì¥: {part_path}")

    # í•©ë³¸ ì €ì¥ì€ í˜¸ì¶œë¶€ì—ì„œ ì²˜ë¦¬
    return "\n\n".join(all_sections)

# --------------------------
# ë³´ì¡°: ì¶œë ¥ ê²½ë¡œ ë³´ì •
# --------------------------
def resolve_output_path(user_in: str, default_path: Path, desired_suffix: str) -> Path:
    """ì‚¬ìš©ìê°€ í´ë”ë§Œ ì¤¬ê±°ë‚˜ í™•ì¥ìê°€ ì—†ìœ¼ë©´ ìë™ ë³´ì •."""
    if not user_in:
        return default_path
    p = Path(user_in)
    if p.is_dir():
        return p / (default_path.name)
    if p.suffix == "":
        return p.with_suffix(desired_suffix)
    # í´ë”ê°€ ì•„ì§ ì—†ìœ¼ë©´ ìƒì„±
    if not p.parent.exists():
        try:
            p.parent.mkdir(parents=True, exist_ok=True)
        except Exception:
            pass
    return p

# --- MODIFIED HELPER FUNCTION ---
# 3. ë¬¸ì„œ ì²˜ë¦¬ ë¡œì§ì„ ë³„ë„ í•¨ìˆ˜ë¡œ ë¶„ë¦¬ (main ë‹¨ìˆœí™”)
def process_structure_mimic_mode(model, raw_text: str, tpl_path: Path, plan_text: str, feature_json_text: Optional[str], tone: str, style: str, leave_blanks: bool, batch_size: int, out_override: str):
    """êµ¬ì¡°-ëª¨ë°© ëª¨ë“œë¥¼ ì‹¤í–‰í•˜ê³ , í•„ìš”ì‹œ LLMìœ¼ë¡œ êµ¬ì¡°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
    # 1. íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ ì œëª© ì¶”ì¶œ ì‹œë„
    headings = extract_headings_heuristic(raw_text)

    # 2. ì‹¤íŒ¨ ì‹œ, LLMìœ¼ë¡œ êµ¬ì¡° ë¶„ì„
    if not headings:
        print("  - íœ´ë¦¬ìŠ¤í‹± ì œëª© íƒì§€ ì‹¤íŒ¨. LLMìœ¼ë¡œ ë¬¸ì„œ êµ¬ì¡°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤...")
        headings = extract_structure_with_llm(model, raw_text)
    
    if not headings:
        print("[ì˜¤ë¥˜] ë¬¸ì„œì—ì„œ ì‘ì„±í•  í•­ëª©(í—¤ë”©)ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¬¸ì„œ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.", file=sys.stderr)
        # LLM ë¶„ì„ë„ ì‹¤íŒ¨í•˜ë©´, ìµœì†Œí•œì˜ ê¸°ë³¸ ëª©ì°¨ë¡œ ë™ì‘í•˜ë„ë¡ í´ë°±
        headings = [
            "1. ê°œìš” (Introduction)",
            "2. ì£¼ìš” ë‚´ìš© (Main Content)",
            "3. ê¸°ëŒ€ íš¨ê³¼ (Expected Outcomes)",
            "4. ê²°ë¡  (Conclusion)"
        ]
        print("  - ê¸°ë³¸ ëª©ì°¨ë¡œ ì´ˆì•ˆ ìƒì„±ì„ ì‹œë„í•©ë‹ˆë‹¤:", headings)

    print(f"  - ì´ {len(headings)}ê°œì˜ í—¤ë”©ì„ ê¸°ë°˜ìœ¼ë¡œ ë¬¸ì„œ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

    stem_for_save = tpl_path.with_name(tpl_path.stem)
    md_all = mimic_structure_with_llm_batch(model, headings, plan_text, feature_json_text, tone, style, leave_blanks, batch_size, stem_for_save)
    default_out = tpl_path.with_name(tpl_path.stem + "_draft.md")
    outp = resolve_output_path(out_override, default_out, ".md")
    outp.write_text(md_all, encoding="utf-8")
    print(f"âœ… í•©ë³¸ ì €ì¥: {outp}")

    if DocxDocument:
        mk_docx = input("â¡ï¸ ì´ˆì•ˆì„ DOCXë¡œë„ ì €ì¥í• ê¹Œìš”? (y/N): ").strip().lower() == "y"
        if mk_docx:
            d2 = DocxDocument()
            # ë§ˆí¬ë‹¤ìš´ í—¤ë”©ì„ ì¢€ ë” ë³´ê¸° ì¢‹ê²Œ ë³€í™˜
            for block in md_all.split('\n\n'):
                lines = block.split('\n')
                if lines[0].startswith('## '):
                    d2.add_heading(lines[0][3:].strip(), level=2)
                    d2.add_paragraph('\n'.join(lines[1:]))
                else:
                    d2.add_paragraph(block)
                d2.add_paragraph() # ë¬¸ë‹¨ ê°„ê²©

            d2_out = outp.with_suffix(".docx")
            d2.save(d2_out.as_posix())
            print(f"(ë³€í™˜) DOCX: {d2_out}")

# --------------------------
# ì¸í„°ë™í‹°ë¸Œ ë©”ì¸
# --------------------------
def main():
    print("ğŸ“„ Auto Document Writer (Gemini 2.5-Flash) â€” Batch\n")

    # 1) ì…ë ¥ ë°›ê¸°
    plan_path_str = input("ğŸ“ ê¸°íšì„œ/ê¸°ëŠ¥ëª…ì„¸ íŒŒì¼ ê²½ë¡œ (.json ë˜ëŠ” .txt): ").strip()
    template_path_str = input("ğŸ“‚ ì‘ì„±í•  ì–‘ì‹ íŒŒì¼ ê²½ë¡œ (.hwpx/.docx/.pdf/.hwp): ").strip()

    tone = input("ğŸ’¬ ì–´íˆ¬/í†¤ (ê¸°ë³¸: ê²©ì‹ ìˆëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ í•œêµ­ì–´): ").strip() or "ê¸°ë³¸"
    style = input("âœï¸ ë¬¸ì¥ ìŠ¤íƒ€ì¼ (ê¸°ë³¸: ê°œì¡°ì‹ ë¶ˆë¦¿): ").strip() or "ê°œì¡°ì‹"
    leave_blanks_input = input("â“ ë¶ˆí™•ì‹¤ì‹œ ë¹ˆì¹¸ ì²˜ë¦¬? (y/N): ").strip().lower()
    leave_blanks = (leave_blanks_input == "y")
    model_name = input("ğŸ¤– Gemini ëª¨ë¸ëª… (ê¸°ë³¸: gemini-2.5-flash): ").strip() or "gemini-2.5-flash"
    if model_name in {"ê¸°ë³¸", "default", "Default"}:
        model_name = "gemini-2.5-flash"

    try:
        batch_size = int(input("ğŸ“¦ ë°°ì¹˜ í¬ê¸°(í•œ ë²ˆì— ìƒì„±í•  í—¤ë”© ìˆ˜, ê¸°ë³¸ 10): ").strip() or "10")
    except ValueError:
        batch_size = 10

    out_override = input("ğŸ’¾ ì¶œë ¥ íŒŒì¼/í´ë” ê²½ë¡œ(ë¯¸ì…ë ¥ ì‹œ ìë™ ê²°ì •): ").strip()

    plan_path = Path(plan_path_str)
    tpl_path = Path(template_path_str)

    if not plan_path.exists():
        print("ê¸°íšì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", file=sys.stderr); sys.exit(1)
    if not tpl_path.exists():
        print("ì–‘ì‹ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", file=sys.stderr); sys.exit(1)

    # 2) ëª¨ë¸ ì¤€ë¹„
    try:
        model = init_gemini(model_name)
    except Exception as e:
        print(f"Gemini ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", file=sys.stderr)
        sys.exit(1)

    # 3) ê¸°íšì„œ ì½ê¸°
    plan_text = read_json_or_text(plan_path)
    feature_json_text = None
    try:
        obj = json.loads(plan_text)
        feature_json_text = json.dumps(obj, ensure_ascii=False, indent=2)
    except Exception:
        pass

    # 4) ë¶„ê¸° ì²˜ë¦¬
    ext = tpl_path.suffix.lower()

    if ext == ".docx":
        if DocxDocument is None:
            print("python-docx ë¯¸ì„¤ì¹˜ë¡œ .docx ì²˜ë¦¬ê°€ ë¶ˆê°€í•©ë‹ˆë‹¤.", file=sys.stderr); sys.exit(1)
        doc, plain = load_docx_and_plaintext(tpl_path)
        keys = detect_placeholders_in_text(plain)
        if keys:
            print(f"[ì¹˜í™˜ ëª¨ë“œ] ê°ì§€ëœ í‚¤: {keys}")
            mapping = fill_placeholders_with_llm(model, keys, plan_text, feature_json_text, tone, style, leave_blanks)
            docx_replace_placeholders(doc, mapping, unsure_to_red=(not leave_blanks))
            default_out = tpl_path.with_name(tpl_path.stem + "_filled.docx")
            outp = resolve_output_path(out_override, default_out, ".docx")
            doc.save(outp.as_posix())
            print(f"âœ… ì™„ë£Œ: {outp}")
        else:
            print("[êµ¬ì¡°-ëª¨ë°© ëª¨ë“œ] DOCX í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ì„¹ì…˜ ìƒì„±(ë°°ì¹˜)")
            process_structure_mimic_mode(model, plain, tpl_path, plan_text, feature_json_text, tone, style, leave_blanks, batch_size, out_override)

    elif ext == ".hwpx":
        xml_blob, keys = hwpx_read_xml(tpl_path)
        if keys:
            print(f"[ì¹˜í™˜ ëª¨ë“œ] HWPX í‚¤ ê°ì§€: {keys}")
            mapping = fill_placeholders_with_llm(model, keys, plan_text, feature_json_text, tone, style, leave_blanks)
            default_out = tpl_path.with_name(tpl_path.stem + "_filled.hwpx")
            outp = resolve_output_path(out_override, default_out, ".hwpx")
            hwpx_replace_and_write(tpl_path, outp, mapping, unsure_to_red=(not leave_blanks))
            print(f"âœ… ì™„ë£Œ: {outp}")
        else:
            print("[êµ¬ì¡°-ëª¨ë°© ëª¨ë“œ] HWPX â†’ Markdown ì´ˆì•ˆ(ë°°ì¹˜)")
            raw_text = xml_blob.decode("utf-8", errors="ignore")
            process_structure_mimic_mode(model, raw_text, tpl_path, plan_text, feature_json_text, tone, style, leave_blanks, batch_size, out_override)

    elif ext == ".pdf":
        print("[êµ¬ì¡°-ëª¨ë°© ëª¨ë“œ] PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ(ìµœëŒ€ 50KB) â†’ Markdown ì´ˆì•ˆ(ë°°ì¹˜)")
        raw = extract_text_from_pdf(tpl_path, max_bytes=50000)
        process_structure_mimic_mode(model, raw, tpl_path, plan_text, feature_json_text, tone, style, leave_blanks, batch_size, out_override)

    elif ext == ".hwp":
        print("[êµ¬ì¡°-ëª¨ë°© ëª¨ë“œ] HWPëŠ” êµ¬ì¡° ì¶”ì¶œ ì œí•œ â†’ Markdown ì´ˆì•ˆ(ë°°ì¹˜)")
        raw = "(HWP í…ìŠ¤íŠ¸ ì¶”ì¶œ ë¯¸êµ¬í˜„: HWPX ë³€í™˜ ê¶Œì¥)"
        # HWPì˜ ê²½ìš° í…ìŠ¤íŠ¸ ì¶”ì¶œì´ ì•ˆë˜ë¯€ë¡œ LLM ë¶„ì„ë„ ì˜ë¯¸ê°€ ì—†ìŒ.
        # ì´ ê²½ìš°ì—ëŠ” ì •ë§ ìµœì†Œí•œì˜ ëª©ì°¨ë§Œ ì œê³µ
        headings = [
            "1. ê³¼ì œ ê°œìš”",
            "2. ì£¼ìš” ë‚´ìš© ë° ì¶”ì§„ ì „ëµ",
            "3. ê¸°ëŒ€íš¨ê³¼ ë° í™œìš©ë°©ì•ˆ"
        ]
        print("  - HWP íŒŒì¼ì€ ë‚´ìš© ë¶„ì„ì´ ë¶ˆê°€í•˜ì—¬ ê¸°ë³¸ ëª©ì°¨ë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
        stem_for_save = tpl_path.with_name(tpl_path.stem)
        md_all = mimic_structure_with_llm_batch(model, headings, plan_text, feature_json_text, tone, style, leave_blanks, batch_size, stem_for_save)
        default_out = tpl_path.with_name(tpl_path.stem + "_draft.md")
        outp = resolve_output_path(out_override, default_out, ".md")
        outp.write_text(md_all, encoding="utf-8")
        print(f"âœ… í•©ë³¸ ì €ì¥: {outp}")

    else:
        print(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í™•ì¥ì: {ext}", file=sys.stderr)
        sys.exit(2)

if __name__ == "__main__":
    main()