import os
import json
import glob
import re
from dotenv import load_dotenv
import google.generativeai as genai
from google.generativeai.types import GenerationConfig

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° Gemini ì„¤ì •
load_dotenv()
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

STOPWORDS = {
    "ê¸°ëŠ¥", "í”„ë¡œì íŠ¸", "ì‚¬ìš©ì", "ì‹œìŠ¤í…œ", "ì„œë¹„ìŠ¤", "êµ¬í˜„", "í”„ë¡œê·¸ë¨", "ì •ë³´", "ê´€ë¦¬",
    "í”„ë¡œì„¸ìŠ¤", "ê²°ê³¼", "ì§€ì›", "ì„¤ì •", "í™œìš©", "ì‘ì—…", "ëª©ì ", "ìš”êµ¬ì‚¬í•­", "í˜ì´ì§€", "ì›¹ì‚¬ì´íŠ¸",
    "ì‚¬ì´íŠ¸", "í”„ë¡œì„¸ìŠ¤", "ìš´ì˜", "ê°œë°œ", "ì‹¤í–‰", "í™˜ê²½", "ì—°ë™", "ì¶œë ¥", "ìˆ˜ì§‘"
}

def find_latest_features_file():
    """ê°€ì¥ ìµœê·¼ì— ìƒì„±ëœ features_*.json íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤."""
    existing = glob.glob("features_*.json")
    if not existing:
        return None
    existing_nums = []
    for f in existing:
        try:
            num_part = f.split("_")[-1].split(".")[0]
            if num_part.isdigit():
                existing_nums.append(int(num_part))
        except (ValueError, IndexError):
            continue
    if not existing_nums:
        return None
    latest_index = max(existing_nums)
    return f"features_{latest_index}.json"

def make_keyword_prompt(document_text):
    """í‚¤ì›Œë“œ ì¶”ì¶œì„ ìœ„í•œ Gemini í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    return f"""
    ë‹¹ì‹ ì€ ì†Œí”„íŠ¸ì›¨ì–´ í”„ë¡œì íŠ¸ ê¸°íšì„œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ì•„ë˜ ê¸°íšì„œì—ì„œ GitHubì—ì„œ ìœ ì‚¬ í”„ë¡œì íŠ¸ë¥¼ ì°¾ëŠ” ë° ì“¸ **êµ¬ì²´ì ì´ê³  ê¸°ìˆ ì ì¸ í‚¤ì›Œë“œ**ë¥¼ 7~12ê°œ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

    - ë°˜ë“œì‹œ 'ê¸°ëŠ¥', 'ì‹œìŠ¤í…œ', 'ì‚¬ìš©ì', 'í”„ë¡œì íŠ¸', 'ì„œë¹„ìŠ¤', 'êµ¬í˜„', 'í”„ë¡œê·¸ë¨'ê³¼ ê°™ì€ ì¼ë°˜ì /ë¶ˆëª…í™•í•œ ë‹¨ì–´ëŠ” ëª¨ë‘ ì œì™¸.
    - í‚¤ì›Œë“œëŠ” í•œê¸€ ë˜ëŠ” ì˜ë¬¸ ëª¨ë‘ í—ˆìš©í•˜ë©°, ê¸°ìˆ ëª…, ë¼ì´ë¸ŒëŸ¬ë¦¬, API, í”„ë ˆì„ì›Œí¬, ì—°ë™ ì„œë¹„ìŠ¤, ë°ì´í„° ì†ŒìŠ¤ ë“±ë§Œ í—ˆìš©.
    - ë‹¨ì¼ ëª…ì‚¬ ë˜ëŠ” 2~3ë‹¨ì–´ ì¡°í•© ê°€ëŠ¥. ì˜ˆì‹œ: 'ì—¬í–‰ ì¼ì • ì¶”ì²œ', 'Google Maps API', 'ì›¹ í¬ë¡¤ë§', 'React', 'Node.js', 'ë°ì´í„° ì‹œê°í™”'.
    - ì¶”ìƒì  ë‹¨ì–´ë‚˜ ë„ˆë¬´ ì§§ê±°ë‚˜ ë¶ˆí•„ìš”í•œ ì—­í• ëª…ì€ ì™„ì „íˆ ë°°ì œí•˜ì„¸ìš”.
    - ë°˜ë“œì‹œ ìˆœìˆ˜ JSON ë°°ì—´ë¡œë§Œ ì¶œë ¥, ì£¼ì„/ì„¤ëª…/ì½”ë“œë¸”ë¡ì€ ì ˆëŒ€ í¬í•¨ ê¸ˆì§€.

    ---
    ğŸ“„ ê¸°íšì„œ:
    {document_text}
    ---
    """

def postprocess_keywords(keywords):
    result = set()
    for kw in keywords:
        k = kw.strip().lower()
        # í•œê¸€/ì˜ë¬¸/ìˆ«ì/ê³µë°±/íŠ¹ìˆ˜ë¬¸ì(-, .)ë§Œ í—ˆìš©
        if not re.match(r"^[a-zA-Zê°€-í£0-9 .\-]+$", k):
            continue
        if k in STOPWORDS or len(k) < 2:
            continue
        result.add(k)
    # ë‹¤ì‹œ ê¸¸ì´ìˆœ + ê°€ë‚˜ë‹¤ìˆœ ì •ë ¬
    return sorted(list(result), key=lambda x: (len(x), x))

def extract_keywords():
    latest_file = find_latest_features_file()
    if not latest_file:
        print("âŒ ì²˜ë¦¬í•  ê¸°íšì„œ íŒŒì¼(features_*.json)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"ğŸ“„ '{latest_file}' íŒŒì¼ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.")
    try:
        with open(latest_file, "r", encoding="utf-8") as f:
            data = json.load(f)
        document_content = data.get("ì •ì œê¸°íšì„œ")
        if not document_content:
            print(f"âŒ '{latest_file}' íŒŒì¼ì— 'ì •ì œê¸°íšì„œ' ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        document_text = json.dumps(document_content, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"âŒ '{latest_file}' íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {e}")
        return

    print("âœ¨ Gemini APIë¥¼ í˜¸ì¶œí•˜ì—¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
    prompt = make_keyword_prompt(document_text)
    model = genai.GenerativeModel("gemini-2.5-flash")
    try:
        response = model.generate_content(prompt, generation_config=GenerationConfig(temperature=0.05))
        result_text = response.text.strip()
        if result_text.startswith("```json"):
            result_text = result_text[7:]
        if result_text.endswith("```"):
            result_text = result_text[:-3]
        result_text = result_text.strip()

        # ê²°ê³¼ íŒŒì‹±
        keywords = json.loads(result_text)
        keywords = postprocess_keywords(keywords)
        if not keywords:
            print("âŒ í›„ì²˜ë¦¬ ê²°ê³¼ ìœ íš¨í•œ í‚¤ì›Œë“œê°€ ë‚¨ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return

        print("\nâœ… ì¶”ì¶œëœ ê²€ìƒ‰ í‚¤ì›Œë“œ(í›„ì²˜ë¦¬ ì ìš©):")
        for keyword in keywords:
            print(f"- {keyword}")

        output_filename = "keywords.json"
        with open(output_filename, "w", encoding="utf-8") as f:
            json.dump(keywords, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ í‚¤ì›Œë“œë¥¼ '{output_filename}' íŒŒì¼ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

    except json.JSONDecodeError:
        print("âŒ Gemini ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        print("--- Gemini ì›ë³¸ ì‘ë‹µ ---")
        print(result_text)
        print("--------------------")
    except Exception as e:
        print(f"âŒ í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    extract_keywords()
