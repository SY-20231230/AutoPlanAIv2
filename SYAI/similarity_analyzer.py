import os
import json
import glob
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import google.generativeai as genai
from google.generativeai.types import GenerationConfig
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° Gemini ì„¤ì •
load_dotenv()
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

def find_latest_features_file():
    """ê°€ì¥ ìµœê·¼ì˜ features_*.json íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤."""
    # keyword_extractor.pyì˜ í•¨ìˆ˜ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    existing = glob.glob("features_*.json")
    if not existing:
        return None
    existing_nums = [int(f.split("_")[-1].split(".")[0]) for f in existing if f.split("_")[-1].split(".")[0].isdigit()]
    if not existing_nums:
        return None
    latest_index = max(existing_nums)
    return f"features_{latest_index}.json"

def load_data():
    """ê¸°íšì„œì™€ GitHub ë¦¬í¬ì§€í† ë¦¬ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    # 1. ê¸°íšì„œ ë¡œë“œ
    plan_file = find_latest_features_file()
    if not plan_file:
        print("âŒ ì²˜ë¦¬í•  ê¸°íšì„œ íŒŒì¼(features_*.json)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, None
    
    try:
        with open(plan_file, "r", encoding="utf-8") as f:
            plan_data = json.load(f).get("ì •ì œê¸°íšì„œ")
        # ê¸°íšì„œ ë‚´ìš©ì„ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ í•©ì¹¨
        plan_text = json.dumps(plan_data, ensure_ascii=False)
    except Exception as e:
        print(f"âŒ '{plan_file}' íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {e}")
        return None, None

    # 2. GitHub ë¦¬í¬ì§€í† ë¦¬ ë°ì´í„° ë¡œë“œ
    try:
        with open("github_repositories.json", "r", encoding="utf-8") as f:
            repos_data = json.load(f)
    except FileNotFoundError:
        print("âŒ 'github_repositories.json' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € github_crawler.pyë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return None, None
    except Exception as e:
        print(f"âŒ 'github_repositories.json' íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {e}")
        return None, None

    return plan_text, repos_data

def analyze_similarity_with_gemini(plan_text, repo_readme, repo_name):
    """Geminië¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°íšì„œì™€ README ê°„ì˜ ìœ ì‚¬ì ê³¼ ì°¨ì´ì ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
    print(f"    âœ¨ Gemini APIë¡œ '{repo_name}' ìƒì„¸ ë¶„ì„ ì¤‘...")
    
    prompt = f"""
    ë‹¹ì‹ ì€ ì†Œí”„íŠ¸ì›¨ì–´ í”„ë¡œì íŠ¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ í”„ë¡œì íŠ¸ ê¸°íšì„œì™€ GitHub ë¦¬í¬ì§€í† ë¦¬ì˜ README ë‚´ìš©ì„ ë¹„êµí•˜ì—¬, ë‘ í”„ë¡œì íŠ¸ ê°„ì˜ í•µì‹¬ì ì¸ ìœ ì‚¬ì ê³¼ ì°¨ì´ì ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

    ---
    ### ğŸ“œ ì›ë³¸ í”„ë¡œì íŠ¸ ê¸°íšì„œ ìš”ì•½:
    {plan_text[:1500]} 
    ---
    ### ğŸ“„ GitHub ë¦¬í¬ì§€í† ë¦¬ README ìš”ì•½:
    {repo_readme[:1500]}
    ---

    ### âœï¸ ë¶„ì„ ìš”ì²­:
    1.  **ìœ ì‚¬ì **: ë‘ í”„ë¡œì íŠ¸ê°€ ì–´ë–¤ ì ì—ì„œ ë¹„ìŠ·í•œ ëª©í‘œ, ê¸°ëŠ¥, ê¸°ìˆ  ìŠ¤íƒì„ ê°€ì§€ê³  ìˆëŠ”ì§€ 2~3ê°€ì§€ í•µì‹¬ í•­ëª©ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
    2.  **ì°¨ì´ì **: ë‘ í”„ë¡œì íŠ¸ì˜ ëª©ì , êµ¬í˜„ ë°©ì‹, ê¸°ëŠ¥ ë²”ìœ„ ë“±ì—ì„œ ë‚˜íƒ€ë‚˜ëŠ” ëª…í™•í•œ ì°¨ì´ì ì„ 2~3ê°€ì§€ í•µì‹¬ í•­ëª©ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.

    ### ğŸ“‹ ì¶œë ¥ í˜•ì‹:
    ì•„ë˜ í˜•ì‹ì— ë§ì¶° ê°„ê²°í•˜ê²Œ Markdownìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.

    **âœ… ìœ ì‚¬ì :**
    * 
    * 

    **âŒ ì°¨ì´ì :**
    * 
    * 
    """
    
    model = genai.GenerativeModel("gemini-1.5-flash")
    try:
        response = model.generate_content(prompt, generation_config=GenerationConfig(temperature=0.2))
        return response.text.strip()
    except Exception as e:
        return f"âŒ Gemini ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

def analyze_similarity():
    """TF-IDFì™€ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ì‚¬ìš©í•˜ì—¬ ìœ ì‚¬ë„ë¥¼ ë¶„ì„í•˜ê³  ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    plan_text, repos_data = load_data()
    if not plan_text or not repos_data:
        return

    # README ë‚´ìš©ì´ ì—†ëŠ” ë¦¬í¬ì§€í† ë¦¬ëŠ” ë¶„ì„ì—ì„œ ì œì™¸
    valid_repos = [repo for repo in repos_data if repo.get("readme")]
    if not valid_repos:
        print("ğŸš« ë¶„ì„í•  README ë‚´ìš©ì´ ìˆëŠ” ë¦¬í¬ì§€í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    repo_readmes = [repo["readme"] for repo in valid_repos]
    
    # TF-IDF ë²¡í„°í™”
    # stop_words='english' ì¶”ê°€í•˜ì—¬ ì¼ë°˜ì ì¸ ì˜ì–´ ë¶ˆìš©ì–´ ì œì™¸
    vectorizer = TfidfVectorizer(stop_words='english')
    all_texts = [plan_text] + repo_readmes
    tfidf_matrix = vectorizer.fit_transform(all_texts)
    
    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    # ì²« ë²ˆì§¸ ë²¡í„°(ê¸°íšì„œ)ì™€ ë‚˜ë¨¸ì§€ ë²¡í„°ë“¤(README) ê°„ì˜ ìœ ì‚¬ë„
    cosine_sim = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:])
    
    # ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ ë¦¬í¬ì§€í† ë¦¬ ì •ë³´ì— ì¶”ê°€
    for i, repo in enumerate(valid_repos):
        repo["similarity"] = cosine_sim[0][i]
        
    # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
    sorted_repos = sorted(valid_repos, key=lambda x: x["similarity"], reverse=True)
    
    # Top 5 ê²°ê³¼
    top_5_repos = sorted_repos[:5]

    # ë¶„ì„ ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    report_lines = []
    
    # --- í„°ë¯¸ë„ ë° íŒŒì¼ í—¤ë” ---
    header = "ğŸ† í”„ë¡œì íŠ¸ ê¸°íšì„œì™€ ê°€ì¥ ìœ ì‚¬í•œ GitHub ë¦¬í¬ì§€í† ë¦¬ Top 5 ğŸ†"
    print("\n" + "="*80)
    print(header)
    print("="*80 + "\n")
    report_lines.append(f"# {header}\n")

    if not top_5_repos:
        no_result_message = "ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ë¦¬í¬ì§€í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤."
        print(no_result_message)
        report_lines.append(no_result_message)
    else:
        for i, repo in enumerate(top_5_repos):
            # í„°ë¯¸ë„ì— ì§„í–‰ ìƒí™© ì¶œë ¥
            repo_header_info = f"#{i+1}: {repo['name']} (â­{repo['stars']})"
            print(repo_header_info)
            print(f"  - URL: {repo['url']}")
            print(f"  - ìœ ì‚¬ë„ ì ìˆ˜: {repo['similarity']:.4f}")

            # íŒŒì¼ì— ì €ì¥í•  ë‚´ìš© ì¶”ê°€ (Markdown í˜•ì‹)
            report_lines.append(f"## {i+1}. {repo['name']} (â­{repo['stars']})")
            report_lines.append(f"- **URL**: <{repo['url']}>")
            report_lines.append(f"- **ìœ ì‚¬ë„ ì ìˆ˜**: {repo['similarity']:.4f}")
            
            # Geminië¥¼ ì´ìš©í•œ ì‹¬ì¸µ ë¶„ì„
            analysis_result = analyze_similarity_with_gemini(plan_text, repo['readme'], repo['name'])
            
            # í„°ë¯¸ë„ ì¶œë ¥ìš© (ë“¤ì—¬ì“°ê¸°)
            indented_analysis = "  " + analysis_result.replace("\n", "\n  ")
            print(f"  - ì‹¬ì¸µ ë¶„ì„:\n{indented_analysis}\n")
            
            # íŒŒì¼ ì €ì¥ìš© (ì›ë³¸ Markdown)
            report_lines.append(f"- **ì‹¬ì¸µ ë¶„ì„**:\n{analysis_result}\n")
    
    # ìµœì¢… ë³´ê³ ì„œ íŒŒì¼ë¡œ ì €ì¥
    report_filename = "analysis_report.md"
    with open(report_filename, "w", encoding="utf-8") as f:
        f.write("\n".join(report_lines))
        
    print(f"\nâœ… ë¶„ì„ ë³´ê³ ì„œë¥¼ '{report_filename}' íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    analyze_similarity()
